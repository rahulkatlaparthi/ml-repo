name: Train and Deploy Model (Full Setup)

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  AZURE_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
  AZURE_RESOURCE_GROUP: ${{ secrets.AZURE_RESOURCE_GROUP }}
  AZURE_WORKSPACE_NAME: ${{ secrets.AZURE_ML_WORKSPACE }}
  LOCATION: eastus

jobs:
  build-train-deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          pip install azure-ai-ml azure-identity mlflow pandas scikit-learn

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Add Azure ML extension
        run: az extension add -n ml -y

      - name: Ensure ML Workspace exists
        run: |
          if ! az ml workspace show --name "$AZURE_WORKSPACE_NAME" --resource-group "$AZURE_RESOURCE_GROUP" >/dev/null 2>&1; then
            echo "Creating Azure ML Workspace..."
            az ml workspace create --name "$AZURE_WORKSPACE_NAME" --resource-group "$AZURE_RESOURCE_GROUP" --location "$LOCATION"
          else
            echo "Workspace already exists."
          fi

      - name: Ensure Compute Cluster exists
        run: |
          COMPUTE_NAME=cpu-cluster
          if ! az ml compute show --name "$COMPUTE_NAME" --resource-group "$AZURE_RESOURCE_GROUP" --workspace-name "$AZURE_WORKSPACE_NAME" >/dev/null 2>&1; then
            echo "Creating Compute Cluster..."
            az ml compute create --name "$COMPUTE_NAME" --type amlcompute --size Standard_E4ds_v4 --min-instances 0 --max-instances 1 --idle-time-before-scale-down 120 --resource-group "$AZURE_RESOURCE_GROUP" --workspace-name "$AZURE_WORKSPACE_NAME"
          else
            echo "Compute cluster already exists."
          fi

      - name: Create and upload sample dataset
        run: |
          mkdir -p data
          cat > data/sample_data.csv <<'CSV_EOF'
          feature1,feature2,feature3,label
          1.2,3.4,5.6,0
          2.3,4.5,6.7,1
          3.1,5.7,8.8,0
          4.2,6.3,9.1,1
          5.0,7.1,10.2,1
          CSV_EOF
          echo "Sample dataset created at data/sample_data.csv"
          az ml data create --name sample-data --path data/sample_data.csv --type uri_file --description "Sample dataset uploaded from GitHub Actions" --resource-group "$AZURE_RESOURCE_GROUP" --workspace-name "$AZURE_WORKSPACE_NAME"

      # - name: Submit training pipeline job
      #   run: |
      #     az configure --defaults group="$AZURE_RESOURCE_GROUP" workspace="$AZURE_WORKSPACE_NAME"
      #     az ml job create --file pipelines/training_pipeline.yml --stream

      - name: Register model from pipeline output
        run: |
          PIPELINE_RUN_ID=$(az ml job list --query "[0].name" -o tsv)
          az ml model create \
            --name my-model \
            --path "azureml://jobs/$PIPELINE_RUN_ID/outputs/model_output" \
            --type custom_model \
            --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
            --workspace-name ${{ env.AZURE_WORKSPACE_NAME }}


      - name: Deploy model as endpoint
        run: |
          ENDPOINT_NAME=sample-endpoint
          az ml online-endpoint create --name "$ENDPOINT_NAME" --file pipelines/endpoint.yml --resource-group "$AZURE_RESOURCE_GROUP" --workspace-name "$AZURE_WORKSPACE_NAME" || true
          az ml online-deployment create --name blue --endpoint "$ENDPOINT_NAME" --model sample-model:1 --instance-type Standard_DS3_v2 --instance-count 1 --resource-group "$AZURE_RESOURCE_GROUP" --workspace-name "$AZURE_WORKSPACE_NAME"
